---
title: 'Data science milestone project'
subtitle : 'Exploratory Data Analysis'
author: "Andyintae"
date: '2020 12 22 '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Intro

The goal of this project is to display the EDA process for building prediction model of text data from SwiftKey.  
It is related with natural language processing(NLP).  
Let's start our first text mining project.  


## Contents
1. Download and load the data sets  
2. Summary statistics about the data sets  
3. Plot and Report  
4. Plan  
  
  
  
## 1. Download and load the data sets

Let's download the 'Coursera-SwiftKey.zip' file and unzip.  
And load the files.  

```{r}
download.file("https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip", destfile = "capstone.zip")
unzip("capstone.zip")
setwd("final/en_US")

en_twit <- readLines(connect1 <- file("en_US.twitter.txt"), encoding = "UTF-8", skipNul = TRUE)
close(connect1)

en_blog <- readLines(connect2 <- file("en_US.blogs.txt"), encoding = "UTF-8", skipNul = TRUE)
close(connect2)

en_news <- readLines(connect3 <- file("en_US.news.txt"), encoding = "UTF-8", skipNul = TRUE)
close(connect3)
```


## 2. Summary statistics about the data sets  

Before start EDA, We need two packages as below :  
```{r}
library(tidyverse)
library(tidytext)
```
  
We should change the data format as tibble and let's combine the data sets.  
```{r}
en_twit <- as_tibble(en_twit)
en_blog <- as_tibble(en_blog)
en_news <- as_tibble(en_news)

dcmt <- bind_rows("twitter" = en_twit, "blogs" = en_blog, "news" = en_news, .id = "category")
names(dcmt) <- c("category", "text")
```

Let's check the data set  
```{r}
glimpse(dcmt)
str(dcmt)
```


```{r}
dcmt %>% group_by(category) %>% 
  summarise(count = n(), max_length = max(nchar(text)))
```
  There are over 2 million lines in the twitter category and there is the longest line seen in the blogs category.  
  
  
# Uni-gram : Build tidy word set  

Let's make sample date set.  
```{r}
set.seed(1222)
dcmt_samp <- dcmt %>% group_by(category) %>% 
  sample_frac(size = .6, replace = FALSE)
```

Count words  
```{r}
dcmt_samp %>% 
  group_by(category) %>% 
  unnest_tokens(word, text) %>% 
  count(category, sort = TRUE)
```

# Count word in each category
```{r}
dcmt_samp_wd <- dcmt_samp %>% 
  group_by(category) %>% 
  unnest_tokens(word, text) %>% 
  anti_join(stop_words) %>% 
  count(category, word, sort = TRUE) %>% 
  mutate(word2 = fct_reorder(word, n))
dcmt_samp_wd %>% top_n(10)
```


# Bi-gram  

Count bigrams  
```{r}
dcmt_samp %>% 
  group_by(category) %>% 
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>% 
  count(category)
```

Count bigrams in each category  
```{r}
dcmt_samp_bigm <- dcmt_samp %>% 
  group_by(category) %>% 
  unnest_tokens(bigram, text, token = "ngrams", n = 2) 

dcmt_samp_bigm_sp <- dcmt_samp_bigm %>% 
  separate(bigram, into = c("word1", "word2"), remove = FALSE, sep = "\\s")

dcmt_samp_bigm_sp_cnt <- dcmt_samp_bigm_sp %>% 
  filter(!word1 %in% stop_words$word & !word2 %in% stop_words$word) %>% 
  count(bigram, sort = TRUE) %>% 
  mutate(bigram2 = fct_reorder(bigram, n))

dcmt_samp_bigm_sp_cnt %>% top_n(10)
```


# Tri-gram  

Count triigrams  
```{r}
dcmt_samp %>% 
  group_by(category) %>% 
  unnest_tokens(trgram, text, token = "ngrams", n = 3) %>% 
  count(category)
```


Count triigrams in each category
```{r}
dcmt_samp_trgm <- dcmt_samp %>% 
  group_by(category) %>% 
  unnest_tokens(trgram, text, token = "ngrams", n = 3)

dcmt_samp_trgm_sp <- dcmt_samp_trgm %>% 
  separate(trgram, into = c("word1", "word2", "word3"), remove = FALSE, sep = "\\s")

dcmt_samp_trgm_sp_cnt <- dcmt_samp_trgm_sp %>% 
  filter(!word1 %in% stop_words$word & 
         !word2 %in% stop_words$word & 
         !word3 %in% stop_words$word) %>% 
  count(trgram, sort = TRUE) %>% 
  mutate(trgram2 = fct_reorder(trgram, n))
```



## Plot and Report  

# plot of Uni-gram  
```{r}
dcmt_samp_wd %>% 
  group_by(category) %>% 
  top_n(10) %>% 
  ggplot(aes(x = word2, y = n, fill = category))+
  geom_col(show.legend = FALSE)+
  coord_flip()+
  labs(title = " Top 10 words", x = "Word", y = "Count")+
  facet_wrap(~category, scales = "free")
```
There are 'time', 'people', 'day', 'love', 'life' and etc in blogs.  
I guess those are related with personal private life story.  

There are many abbreviation and slang in twitter.  


# plot of Bi-gram  
```{r}
dcmt_samp_bigm_sp_cnt %>% 
  group_by(category) %>% 
  top_n(10) %>% 
  ggplot(aes(x = bigram2, y = n, fill = category))+
  geom_col(show.legend = FALSE)+
  coord_flip()+
  labs(title = " Top 10 Bi-grams", x = "Bi-gram", y = "Count")+
  facet_wrap(~category, scales = "free")
```
We can see 'ice cream,', 'week age', 'real life', 'feel free' which are seemed to be personal matters.  
Interestingly, there are many times and name of place in news.  


# plot of Tri-gram  
```{r}

dcmt_samp_trgm_sp_cnt %>% 
  group_by(category) %>% 
  top_n(10) %>% 
  ggplot(aes(x = trgram2, y = n, fill = category))+
  geom_col(show.legend = FALSE)+
  coord_flip()+
  labs(title = " Top 10 Tri-grams", x = "Tri-gram", y = "Count")+
  facet_wrap(category, scales = "free")
```

There are many times in news.  
And there are tri-grams related with special day.  
  


## 4. Plan  

Next time, I will creating a prediction algorithm and Shiny app.  
Thank you for your kind review.  
  
    
    
